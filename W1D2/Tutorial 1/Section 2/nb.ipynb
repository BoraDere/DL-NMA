{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGraph:\n",
    "  \"\"\"\n",
    "  Implementing Simple Computational Graph\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, w, b):\n",
    "    \"\"\"\n",
    "    Initializing the SimpleGraph\n",
    "\n",
    "    Args:\n",
    "      w: float\n",
    "        Initial value for weight\n",
    "      b: float\n",
    "        Initial value for bias\n",
    "\n",
    "    Returns:\n",
    "      Nothing\n",
    "    \"\"\"\n",
    "    assert isinstance(w, float)\n",
    "    assert isinstance(b, float)\n",
    "    self.w = torch.tensor([w], requires_grad=True)\n",
    "    self.b = torch.tensor([b], requires_grad=True)\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\"\n",
    "    Forward pass\n",
    "\n",
    "    Args:\n",
    "      x: torch.Tensor\n",
    "        1D tensor of features\n",
    "\n",
    "    Returns:\n",
    "      prediction: torch.Tensor\n",
    "        Model predictions\n",
    "    \"\"\"\n",
    "    assert isinstance(x, torch.Tensor)\n",
    "    #################################################\n",
    "    ## Implement the the forward pass to calculate prediction\n",
    "    ## Note that prediction is not the loss, but the value after `tanh`\n",
    "    # Complete the function and remove or comment the line below\n",
    "    raise NotImplementedError(\"Forward Pass `forward`\")\n",
    "    #################################################\n",
    "    prediction = ...\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def sq_loss(y_true, y_prediction):\n",
    "  \"\"\"\n",
    "  L2 loss function\n",
    "\n",
    "  Args:\n",
    "    y_true: torch.Tensor\n",
    "      1D tensor of target labels\n",
    "    y_prediction: torch.Tensor\n",
    "      1D tensor of predictions\n",
    "\n",
    "  Returns:\n",
    "    loss: torch.Tensor\n",
    "      L2-loss (squared error)\n",
    "  \"\"\"\n",
    "  assert isinstance(y_true, torch.Tensor)\n",
    "  assert isinstance(y_prediction, torch.Tensor)\n",
    "  #################################################\n",
    "  ## Implement the L2-loss (squred error) given true label and prediction\n",
    "  # Complete the function and remove or comment the line below\n",
    "  raise NotImplementedError(\"Loss function `sq_loss`\")\n",
    "  #################################################\n",
    "  loss = ...\n",
    "  return loss\n",
    "\n",
    "\n",
    "\n",
    "feature = torch.tensor([1])  # Input tensor\n",
    "target = torch.tensor([7])  # Target tensor\n",
    "## Uncomment to run\n",
    "# simple_graph = SimpleGraph(-0.5, 0.5)\n",
    "# print(f\"initial weight = {simple_graph.w.item()}, \"\n",
    "#       f\"\\ninitial bias = {simple_graph.b.item()}\")\n",
    "# prediction = simple_graph.forward(feature)\n",
    "# square_loss = sq_loss(target, prediction)\n",
    "# print(f\"for x={feature.item()} and y={target.item()}, \"\n",
    "#       f\"prediction={prediction.item()}, and L2 Loss = {square_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial weight = -0.5, \n",
      "initial bias = 0.5\n",
      "for x=1 and y=7, prediction=0.0, and L2 Loss = 49.0\n"
     ]
    }
   ],
   "source": [
    "class SimpleGraph:\n",
    "  \"\"\"\n",
    "  Implementing Simple Computational Graph\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, w, b):\n",
    "    \"\"\"\n",
    "    Initializing the SimpleGraph\n",
    "\n",
    "    Args:\n",
    "      w: float\n",
    "        Initial value for weight\n",
    "      b: float\n",
    "        Initial value for bias\n",
    "\n",
    "    Returns:\n",
    "      Nothing\n",
    "    \"\"\"\n",
    "    assert isinstance(w, float)\n",
    "    assert isinstance(b, float)\n",
    "    self.w = torch.tensor([w], requires_grad=True)\n",
    "    self.b = torch.tensor([b], requires_grad=True)\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\"\n",
    "    Forward pass\n",
    "\n",
    "    Args:\n",
    "      x: torch.Tensor\n",
    "        1D tensor of features\n",
    "\n",
    "    Returns:\n",
    "      prediction: torch.Tensor\n",
    "        Model predictions\n",
    "    \"\"\"\n",
    "    assert isinstance(x, torch.Tensor)\n",
    "    prediction = torch.tanh(self.w * x + self.b)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def sq_loss(y_true, y_prediction):\n",
    "  \"\"\"\n",
    "  L2 loss function\n",
    "\n",
    "  Args:\n",
    "    y_true: torch.Tensor\n",
    "      1D tensor of target labels\n",
    "    y_prediction: torch.Tensor\n",
    "      1D tensor of predictions\n",
    "\n",
    "  Returns:\n",
    "    loss: torch.Tensor\n",
    "      L2-loss (squared error)\n",
    "  \"\"\"\n",
    "  assert isinstance(y_true, torch.Tensor)\n",
    "  assert isinstance(y_prediction, torch.Tensor)\n",
    "  loss = (y_true - y_prediction) ** 2\n",
    "  return loss\n",
    "\n",
    "\n",
    "\n",
    "feature = torch.tensor([1])  # Input tensor\n",
    "target = torch.tensor([7])  # Target tensor\n",
    "# Uncomment to run\n",
    "simple_graph = SimpleGraph(-0.5, 0.5)\n",
    "print(f\"initial weight = {simple_graph.w.item()}, \"\n",
    "      f\"\\ninitial bias = {simple_graph.b.item()}\")\n",
    "prediction = simple_graph.forward(feature)\n",
    "square_loss = sq_loss(target, prediction)\n",
    "print(f\"for x={feature.item()} and y={target.item()}, \"\n",
    "      f\"prediction={prediction.item()}, and L2 Loss = {square_loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function = <AddBackward0 object at 0x000001B8D6FBE650>\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1.0], requires_grad=True)\n",
    "b = torch.tensor([-1.0], requires_grad=True)\n",
    "c = a + b\n",
    "print(f'Gradient function = {c.grad_fn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for prediction = <TanhBackward0 object at 0x000001B8AD6A5E70>\n",
      "Gradient function for loss = <PowBackward0 object at 0x000001B8AD6A7880>\n"
     ]
    }
   ],
   "source": [
    "print(f'Gradient function for prediction = {prediction.grad_fn}')\n",
    "print(f'Gradient function for loss = {square_loss.grad_fn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True])\n",
      "tensor([True])\n"
     ]
    }
   ],
   "source": [
    "# Analytical gradients (Remember detaching)\n",
    "ana_dloss_dw = - 2 * feature * (target - prediction.detach())*(1 - prediction.detach()**2)\n",
    "ana_dloss_db = - 2 * (target - prediction.detach())*(1 - prediction.detach()**2)\n",
    "\n",
    "square_loss.backward()  # First we should call the backward to build the graph\n",
    "autograd_dloss_dw = simple_graph.w.grad  # We calculate the derivative w.r.t weights\n",
    "autograd_dloss_db = simple_graph.b.grad  # We calculate the derivative w.r.t bias\n",
    "\n",
    "print(ana_dloss_dw == autograd_dloss_dw)\n",
    "print(ana_dloss_db == autograd_dloss_db)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
